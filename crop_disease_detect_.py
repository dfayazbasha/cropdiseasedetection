# -*- coding: utf-8 -*-
"""give me code and datasets for crop disease detect...

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kk5C4zGc2QQ0EAAquO7NddrWwfmUaEf1
"""

for root, dirs, files in os.walk(data_dir):
    print(f"Directory: {root}, Contains Folders: {dirs}, Contains Files: {len(files)}")

import os

# List contents of the directory
for root, dirs, files in os.walk(data_dir):
    print(f"Root: {root}")
    print(f"Dirs: {dirs}")
    print(f"Files: {files}")

import os

# Path to the extracted directory
extracted_dir = '/content/'

# List the contents to find the extracted folder
extracted_contents = os.listdir(extracted_dir)
print("Contents of the extracted directory:")
for item in extracted_contents:
    print(item)

import zipfile
import os

# Path to your uploaded zip file
zip_file_path = '/content/archive.zip'  # Change to your actual zip file name

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall('/content/')

# Path to the extracted directory
data_dir = 'plantvillage'  # Update this with the actual name of the extracted folder

# List contents to verify
for root, dirs, files in os.walk(data_dir):
    print(f"Root: {root}")
    print(f"Dirs: {dirs}")
    print(f"Files: {files}")

import zipfile
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Path to your uploaded zip file
zip_file_path = '/content/archive.zip'  # Replace 'your_dataset.zip' with the actual name of your zip file

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall('/content/')

# List contents to identify the extracted folder
extracted_contents = os.listdir('/content/')
print("Contents of the extracted directory:")
for item in extracted_contents:
    print(item)

# Assume the extracted folder name is 'plant_diseases', update accordingly
data_dir = 'plantvillage'  # Update this with the actual name of the extracted folder
#data_dir = ''  # Replace with actual folder name

# Data Augmentation and Rescaling
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 80% for training, 20% for validation

# Load Training Data
train_set = train_datagen.flow_from_directory(
    data_dir,                    # This should now point to the folder with class subdirectories
    target_size=(64, 64),        # Resize images to 64x64 pixels
    batch_size=32,               # Batch size
    class_mode='categorical',    # Multi-class classification
    subset='training'            # Use this subset for training
)

# Load Validation Data
validation_set = train_datagen.flow_from_directory(
    data_dir,                    # This should now point to the folder with class subdirectories
    target_size=(64, 64),        # Resize images to 64x64 pixels
    batch_size=32,               # Batch size
    class_mode='categorical',    # Multi-class classification
    subset='validation'          # Use this subset for validation
)

import os

# Check contents of the directories
print("Contents of 'plantvillage':")
for root, dirs, files in os.walk('/content/plantvillage'):
    print(f"Root: {root}")
    print(f"Dirs: {dirs}")
    print(f"Files: {files}")

print("\nContents of 'PlantVillage':")
for root, dirs, files in os.walk('/content/PlantVillage'):
    print(f"Root: {root}")
    print(f"Dirs: {dirs}")
    print(f"Files: {files}")

data_dir = '/content/PlantVillage'  # Update if this folder contains your dataset

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data Augmentation and Rescaling
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 80% for training, 20% for validation

# Load Training Data
train_set = train_datagen.flow_from_directory(
    data_dir,                    # Updated to the correct path
    target_size=(64, 64),        # Resize images to 64x64 pixels
    batch_size=32,               # Batch size
    class_mode='categorical',    # Multi-class classification
    subset='training'            # Use this subset for training
)

# Load Validation Data
validation_set = train_datagen.flow_from_directory(
    data_dir,                    # Updated to the correct path
    target_size=(64, 64),        # Resize images to 64x64 pixels
    batch_size=32,               # Batch size
    class_mode='categorical',    # Multi-class classification
    subset='validation'          # Use this subset for validation
)

import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
import matplotlib.pyplot as plt

# Path to the image you want to test
image_path = '/content/0a8a68ee-f587-4dea-beec-79d02e7d3fa4___RS_Early.B 8461.JPG'  # Replace with your image file path

# Load and preprocess the image
img = image.load_img(image_path, target_size=(64, 64))  # Target size should match the input size of your model
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)  # Use the appropriate preprocessing function for your model

# Display the image
plt.imshow(img)
plt.axis('off')
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(15, activation='softmax')  # Number of classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Example Data Augmentation and Data Generators (adjust paths)
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
train_set = train_datagen.flow_from_directory('/content/PlantVillage', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='training')
validation_set = train_datagen.flow_from_directory('/content/PlantVillage', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='validation')

# Train the model
model.fit(train_set, validation_data=validation_set, epochs=10)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense

# Load pre-trained VGG16 model (exclude top layers)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))

# Add custom layers
x = base_model.output
x = Flatten()(x)
x = Dense(64, activation='relu')(x)
predictions = Dense(15, activation='softmax')(x)  # Adjust number of classes

model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Define and train or load the model first
# model = your_model_definition_or_loading_code_here

# Then proceed to make predictions
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions[0])

# Import necessary libraries
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

# Define and compile the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(15, activation='softmax')  # Adjust number of classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Data augmentation and loading
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
train_set = train_datagen.flow_from_directory('/content/PlantVillage', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='training')
validation_set = train_datagen.flow_from_directory('/content/PlantVillage', target_size=(64, 64), batch_size=32, class_mode='categorical', subset='validation')

# Train the model
model.fit(train_set, validation_data=validation_set, epochs=10)

# Save the model (optional)
model.save('/content/crop_disease_model.h5')

# Load the model (if needed later)
from tensorflow.keras.models import load_model
model = load_model('/content/crop_disease_model.h5')

# Load and preprocess the image
image_path = '/content/0a8a68ee-f587-4dea-beec-79d02e7d3fa4___RS_Early.B 8461.JPG'  # Replace with your image path
img = image.load_img(image_path, target_size=(64, 64))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array / 255.0  # Ensure the same preprocessing as training

# Make a prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions[0])

# Map to class labels and treatments
class_labels = ['Healthy', 'Diseased_Leaf_Curl', 'Diseased_Leaf_Blight', ...]  # Update with your class labels
treatments = {
    'Healthy': 'No treatment needed.',
    'Diseased_Leaf_Curl': 'Use a fungicide...',

}

predicted_disease = class_labels[predicted_class]
print(f"Predicted Disease: {predicted_disease}")
print(f"Recommended Treatment: {treatments.get(predicted_disease, 'No treatment information available.')}")